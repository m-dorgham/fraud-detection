# fraud-detection
This is a notebook for exploring and comparing different methods for anomaly detection. I explore at least one method in each learning paradigm, namely, supervised, unsupervised, and semi-supervised learning. In supervised learning I test a simple linear classifier (logistic regression) with the traditional technique of downsampling to handle data imbalance. In unsupervised learning, I test autoencoders, and deep one-class classification. In semi-supervised learning, I test a recent method called Deep Semi-supervised Anamoly Detection (Deep SAD) which is an extension of deep one-class classification. 

This is the [link](https://www.kaggle.com/mdorgham/fraud-detection-comparing-4-methods) for my notebook on kaggle.
